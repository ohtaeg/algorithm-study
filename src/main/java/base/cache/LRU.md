# LRU 캐시 알고리즘
- Least Recently Used, 캐사에서 메모리를 다루기 위해 사용되는 알고리즘
- 캐시가 사용하는 양은 한정적, 제한된 리소스를 잘 활용해야 되기에
- 최근에 사용된 적이 없는 캐시의 메모리부터 대체를 하며 새로운 데이터로 교체

## 동작 원리
- head 와 tail 을 포인터로 이용한다.
- head에 가까울수록 가장 최근에 사용된 항목이다.
- tail에 가까울수록 사용 빈도가 가장 오래된 항목으로써, 새로운 데이터 삽입시 cache 용량이 가득일 경우 tail을 먼저 삭제된다.
- LRU Cache 구현은 `더블 링크드 리스트`를 통해 구현한다.
- 다만 링크드 리스트로 구현을하면 검색시 순차검색으로 인해 시간복잡도가 O(N)이 된다.
- 검색시 시간복잡도 O(N)을 O(1)로 상수가 되려면 랜덤 access가 가능해야한다.
- 이를 가능하게 해주는 자료구조는 Map으로써 `Map`과 `더블 링크드 리스트`를 통해 구현한다.
    - 검색시 (get) O(1)
    - 삽입시 (put) O(1)의 성능을 가져올 수 있다. 


